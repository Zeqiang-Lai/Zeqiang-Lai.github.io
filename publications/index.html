<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Zeqiang Lai</title> <meta name="author" content="Zeqiang Lai"> <meta name="description" content="The year indicates the time when the work is mostly finished. &lt;br&gt; * indicates equal contribution."> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link href="https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,300;0,400;0,500;0,600;1,400;1,500;1,600&amp;display=swap" rel="stylesheet"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://zeqiang-lai.github.io/publications/"> <link rel="stylesheet" href="https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title" href="/">Zeqiang Lai<span class="cn-name"> (赖泽强) </span></a> <div class="navbar-brand social"> <span class="contact-icon"><a href="https://scholar.google.com/citations?user=WUMu1KkAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/Zeqiang-Lai" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://twitter.com/ZeqiangLai" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> <a href="mailto:%6C%61%69%7A%65%71%69%61%6E%67@%6F%75%74%6C%6F%6F%6B.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> </span> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/softwares/">Softwares</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h2 class="post-title">Publications</h2> <p class="post-description">The year indicates the time when the work is mostly finished. <br> * indicates equal contribution.</p> </header> <article> <div class="publications"> <h3 class="year">2025</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/studio.jpeg"></div> <div id="lei2025hunyuan3dstudioendtoendai" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2509.12815" rel="external nofollow noopener" target="_blank">Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2509.12815.</em> <nobr class="links" style="font-weight: 600;"> </nobr> </span> <br> <div class="author"> Biwen Lei, Yang Li, Xinhai Liu, Shuhui Yang, Lixin Xu, Jingwei Huang, Ruining Tang, Haohan Weng, Jian Liu, Jing Xu, Zhen Zhou, Yiling Zhu, and <span class="more-authors" title="click to view 88 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '88 more authors' ? 'Jiankai Xing, Jiachen Xu, Changfeng Ma, Xinhao Yan, Yunhan Yang, Chunshi Wang, Duoteng Xu, Xueqi Ma, Yuguang Chen, Jing Li, Mingxin Yang, Sheng Zhang, Yifei Feng, Xin Huang, Di Luo, Zebin He, Puhua Jiang, Changrong Hu, Zihan Qin, Shiwei Miao, Haolin Liu, Yunfei Zhao, Zeqiang Lai, Qingxiang Lin, Zibo Zhao, Kunhong Li, Xianghui Yang, Huiwen Shi, Xin Yang, Yuxuan Wang, Zebin Yao, Yihang Lian, Sicong Liu, Xintong Han, Wangchen Qin, Caisheng Ouyang, Jianyin Liu, Tianwen Yuan, Shuai Jiang, Hong Duan, Yanqi Niu, Wencong Lin, Yifu Sun, Shirui Huang, Lin Niu, Gu Gong, Guojian Xiao, Bojian Zheng, Xiang Yuan, Qi Chen, Jie Xiao, Dongyang Zheng, Xiaofeng Yang, Kai Liu, Jianchen Zhu, Lifu Wang, Qinglin Lu, Jie Liu, Liang Dong, Fan Jiang, Ruibin Chen, Lei Wang, Chao Zhang, Jiaxin Lin, Hao Zhang, Zheng Ye, Peng He, Runzhou Wu, Yinhe Wu, Jiayao Du, Jupeng Chen, Xinyue Mao, Dongyuan Guo, Yixuan Tang, Yulin Tsai, Yonghao Tan, Jiaao Yu, Junlin Yu, Keren Zhang, Yifan Li, Peng Chen, Tian Liu, Di Wang, Yuhong Liu, Linus, Jie Jiang, Zhuo Chen, Chunchao Guo' : '88 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">88 more authors</span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/xpart.jpeg"></div> <div id="yan2025xparthighfidelitystructure" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2509.08643" rel="external nofollow noopener" target="_blank">X-Part: High Fidelity and Structure Coherent Shape Decomposition</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2509.08643.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/Tencent-Hunyuan/Hunyuan3D-Part" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> Xinhao Yan, Jiachen Xu, Yang Li, Changfeng Ma, Yunhan Yang, Chunshi Wang, Zibo Zhao, <em>Zeqiang Lai</em>, Yunfei Zhao, Zhuo Chen, and Chunchao Guo</div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hunyuan3d_25.jpg"></div> <div id="lai2025hunyuan3d" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2506.16504" rel="external nofollow noopener" target="_blank">Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2506.16504.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/Zeqiang-Lai/LATTICE" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai*</em>, Yunfei Zhao*, Haolin Liu*, Zibo Zhao, Qingxiang Lin, Huiwen Shi, Xianghui Yang, Mingxin Yang*, Shuhui Yang*, Yifei Feng*, Sheng Zhang, Xin Huang, and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Di Luo, Fan Yang, Fang Yang, Lifu Wang, Sicong Liu, Yixuan Tang, Yulin Cai, Zebin He, Tian Liu, Yuhong Liu, Jie Jiang, Linus, Jingwei Huang, Chunchao Guo' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">14 more authors</span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hunyuan3d_21.jpg"></div> <div id="hunyuan3d2025hunyuan3d" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2506.15442" rel="external nofollow noopener" target="_blank">Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2506.15442.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/Tencent-Hunyuan/Hunyuan3D-2.1" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> Shuhui Yang, Mingxin Yang, Yifei Feng, Xin Huang, Sheng Zhang, Zebin He, Di Luo, Haolin Liu, Yunfei Zhao, Qingxiang Lin, <em>Zeqiang Lai</em>, Xianghui Yang, and <span class="more-authors" title="click to view 40 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '40 more authors' ? 'Huiwen Shi, Zibo Zhao, Bowen Zhang, Hongyu Yan, Lifu Wang, Sicong Liu, Jihong Zhang, Meng Chen, Liang Dong, Yiwen Jia, Yulin Cai, Jiaao Yu, Yixuan Tang, Dongyuan Guo, Junlin Yu, Hao Zhang, Zheng Ye, Peng He, Runzhou Wu, Shida Wei, Chao Zhang, Yonghao Tan, Yifu Sun, Lin Niu, Shirui Huang, Bojian Zheng, Shu Liu, Shilin Chen, Xiang Yuan, Xiaofeng Yang, Kai Liu, Jianchen Zhu, Peng Chen, Tian Liu, Di Wang, Yuhong Liu, Linus, Jie Jiang, Jingwei Huang, Chunchao Guo' : '40 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">40 more authors</span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/flashvdm.jpg"></div> <div id="lai2025unleashingvecsetdiffusionmodel" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2503.16302" rel="external nofollow noopener" target="_blank">FlashVDM: Unleashing Vecset Diffusion Model for Fast Shape Generation</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> ICCV 2025 Highlight, </nobr> <em>International Conference on Computer Vision.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/Tencent/FlashVDM" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai*</em>, Yunfei Zhao*, Zibo Zhao, Haolin Liu, Fuyun Wang, Huiwen Shi, Xianghui Yang, Qingxiang Lin, Jingwei Huang, Yuhong Liu, Jie Jiang, Chunchao Guo, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Xiangyu Yue' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">1 more author</span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hunyuan3d_2.jpg"></div> <div id="zhao2025hunyuan3d20scalingdiffusion" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2501.12202" rel="external nofollow noopener" target="_blank">Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2501.12202.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://3d-models.hunyuan.tencent.com/" target="_blank" rel="external nofollow noopener">Website</a>] [<a href="https://github.com/Tencent/Hunyuan3D-2" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> Zibo Zhao*, <em>Zeqiang Lai*</em>, Qingxiang Lin*, Yunfei Zhao*, Haolin Liu, Shuhui Yang*, Yifei Feng*, Mingxin Yang*, Sheng Zhang*, Xianghui Yang, Huiwen Shi, Sicong Liu, and <span class="more-authors" title="click to view 59 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '59 more authors' ? 'Junta Wu, Yihang Lian, Fan Yang, Ruining Tang, Zebin He, Xinzhou Wang, Jian Liu, Xuhui Zuo, Zhuo Chen, Biwen Lei, Haohan Weng, Jing Xu, Yiling Zhu, Xinhai Liu, Lixin Xu, Changrong Hu, Tianyu Huang, Lifu Wang, Jihong Zhang, Meng Chen, Liang Dong, Yiwen Jia, Yulin Cai, Jiaao Yu, Yixuan Tang, Hao Zhang, Zheng Ye, Peng He, Runzhou Wu, Chao Zhang, Yonghao Tan, Jie Xiao, Yangyu Tao, Jianchen Zhu, Jinbao Xue, Kai Liu, Chongqing Zhao, Xinming Wu, Zhichao Hu, Lei Qin, Jianbing Peng, Zhan Li, Minghui Chen, Xipeng Zhang, Lin Niu, Paige Wang, Yingkai Wang, Haozhao Kuang, Zhongyi Fan, Xu Zheng, Weihao Zhuang, YingPing He, Tian Liu, Yong Yang, Di Wang, Yuhong Liu, Jie Jiang, Jingwei Huang, Chunchao Guo' : '59 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">59 more authors</span> </div> </div> </div> </li> </ol> <h3 class="year">2024</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/mulan.png"></div> <div id="xing2024mulan" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2412.01271" rel="external nofollow noopener" target="_blank">MuLan: Adapting Multilingual Diffusion Models for Hundreds of Languages with Negligible Cost</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> ICML 2025, </nobr> <em>International Conference on Machine Learning.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/mulanai/MuLan" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> Sen Xing*, Muyan Zhong*, <em>Zeqiang Lai*</em>, Liangchen Li, Jiawen Liu, Yaohui Wang, <a href="https://jifengdai.org/" rel="external nofollow noopener" target="_blank">Jifeng Dai</a>, and <a href="https://whai362.github.io/" rel="external nofollow noopener" target="_blank">Wenhai Wang</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/flexitex.png"></div> <div id="jiang2024flexitex" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2409.12431" rel="external nofollow noopener" target="_blank">Flexitex: Enhancing Texture Generation with Visual Guidance</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> AAAI 2025, </nobr> <em>AAAI Conference on Artificial Intelligence.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://flexitex.github.io/FlexiTex/" target="_blank" rel="external nofollow noopener">Website</a>] </nobr> </span> <br> <div class="author"> DaDong Jiang, Xianghui Yang, Zibo Zhao, Sheng Zhang, Jiaao Yu, <em>Zeqiang Lai</em>, Shaoxiong Yang, Chunchao Guo, Xiaobo Zhou, and Zhihui Ke</div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/bpt.png"></div> <div id="weng2024scaling" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2411.07025" rel="external nofollow noopener" target="_blank">Scaling Mesh Generation via Compressive Tokenization</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> CVPR 2025, </nobr> <em>The IEEE/CVF Conference on Computer Vision and Pattern Recognition.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://whaohan.github.io/bpt/" target="_blank" rel="external nofollow noopener">Website</a>] [<a href="https://github.com/whaohan/bpt" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> Haohan Weng, Zibo Zhao, Biwen Lei, Xianghui Yang, Jian Liu, <em>Zeqiang Lai</em>, Zhuo Chen, Yuhong Liu, Jie Jiang, Chunchao Guo, and  others</div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/visionllmv2.png"></div> <div id="wu2024visionllm" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2406.08394" rel="external nofollow noopener" target="_blank">VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> NeurIPS 2024, </nobr> <em>Conference on Neural Information Processing Systems.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/OpenGVLab/VisionLLM/tree/main/VisionLLMv2" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> Jiannan Wu*, Muyan Zhong*, Sen Xing*, <em>Zeqiang Lai*</em>, <a href="https://scholar.google.com/citations?user=btgwZosAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhaoyang Liu*</a>, <a href="https://whai362.github.io/" rel="external nofollow noopener" target="_blank">Wenhai Wang*</a>, Zhe Chen, Xizhou Zhu, Lewei Lu, Tong Lu, and  others</div> </div> </div> </li> </ol> <h3 class="year">2023</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/controlllm.png"></div> <div id="liu2023controlllm" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2310.17796" rel="external nofollow noopener" target="_blank">ControlLLM: Augment Language Models with Tools by Searching on Graphs</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> ECCV 2024, </nobr> <em>European Conference on Computer Vision.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/OpenGVLab/ControlLLM" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <a href="https://scholar.google.com/citations?user=btgwZosAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhaoyang Liu*</a>, <em>Zeqiang Lai*</em>, Gao Zhangwei, Erfei Cui, Zhiheng Li, Xizhou Zhu, Lewei Lu, Qifeng Chen, <a href="http://mmlab.siat.ac.cn/yuqiao/" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, <a href="https://jifengdai.org/" rel="external nofollow noopener" target="_blank">Jifeng Dai</a>, and Wang Wenhai</div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/minidalle3.png"></div> <div id="minidalle3" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2310.07653" rel="external nofollow noopener" target="_blank">Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2310.07653.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://minidalle3.github.io/" target="_blank" rel="external nofollow noopener">Website</a>] [<a href="https://github.com/Zeqiang-Lai/Mini-DALLE3" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai</em>, Xizhou Zhu, <a href="https://jifengdai.org/" rel="external nofollow noopener" target="_blank">Jifeng Dai</a>, <a href="http://mmlab.siat.ac.cn/yuqiao/" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://whai362.github.io/" rel="external nofollow noopener" target="_blank">Wenhai Wang</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/dprox.png"></div> <div id="lai2023dprox" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://light.princeton.edu/wp-content/uploads/2023/05/deltaprox-main.pdf" rel="external nofollow noopener" target="_blank">∇-Prox: Differentiable Proximal Algorithm Modeling for Large-Scale Optimization</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> SIGGRAPH 2023, </nobr> <em>ACM Transactions on Graphics.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://light.princeton.edu/publication/delta_prox/" target="_blank" rel="external nofollow noopener">Website</a>] [<a href="https://github.com/princeton-computational-imaging/Delta-Prox" target="_blank" rel="external nofollow noopener">Code</a>] [<a href="https://github.com/princeton-computational-imaging/Delta-Prox/tree/main/notebooks" target="_blank" rel="external nofollow noopener">Colab</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai*</em>, <a href="https://kxwei.net/" rel="external nofollow noopener" target="_blank">Kaixuan Wei*</a>, <a href="https://ying-fu.github.io/" rel="external nofollow noopener" target="_blank">Ying Fu</a>, <a href="https://scholar.google.com/citations?user=_GrMtGgAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Philipp Härtel</a>, and <a href="https://www.cs.princeton.edu/~fheide/" rel="external nofollow noopener" target="_blank">Felix Heide</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/interngpt.gif"></div> <div id="liu2023internchat" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2305.05662" rel="external nofollow noopener" target="_blank">InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2305.05662.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://igpt.opengvlab.com/" target="_blank" rel="external nofollow noopener">Website</a>] [<a href="https://github.com/OpenGVLab/InternGPT" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <a href="https://scholar.google.com/citations?user=btgwZosAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Zhaoyang Liu*</a>, <a href="https://github.com/yinanhe" rel="external nofollow noopener" target="_blank">Yinan He*</a>, <a href="https://whai362.github.io/" rel="external nofollow noopener" target="_blank">Wenhai Wang*</a>, Weiyun Wang*, Yi Wang*, <a href="https://www.shoufachen.com/" rel="external nofollow noopener" target="_blank">Shoufa Chen*</a>, Qinglong Zhang*, <em>Zeqiang Lai*</em>, Yang Yang, Qingyun Li, Jiashuo Yu, Kunchang Li, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Zhe Chen, Xue Yang, Xizhou Zhu, Yali Wang, Limin Wang, Ping Luo, Jifeng Dai, Yu Qiao' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">8 more authors</span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/ddps.png"></div> <div id="lai2023ddps" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2306.01721" rel="external nofollow noopener" target="_blank">Denoising Diffusion Semantic Segmentation with Mask Prior Modeling</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2306.01721.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/OpenGVLab/DDPS" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai*</em>, <a href="https://github.com/duanduanduanyuchen" rel="external nofollow noopener" target="_blank">Yuchen Duan*</a>, <a href="https://jifengdai.org/" rel="external nofollow noopener" target="_blank">Jifeng Dai</a>, Ziheng Li, <a href="https://ying-fu.github.io/" rel="external nofollow noopener" target="_blank">Ying Fu</a>, <a href="https://www.ee.cuhk.edu.hk/~hsli/" rel="external nofollow noopener" target="_blank">Hongsheng Li</a>, <a href="http://mmlab.siat.ac.cn/yuqiao/" rel="external nofollow noopener" target="_blank">Yu Qiao</a>, and <a href="https://whai362.github.io/" rel="external nofollow noopener" target="_blank">Wenhai Wang</a> </div> </div> </div> </li> </ol> <h3 class="year">2022</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hsdt.png"></div> <div id="lai2022hsdt" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2303.09040" rel="external nofollow noopener" target="_blank">Hybrid Spectral Denoising Transformer with Guided Attention</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> ICCV 2023, </nobr> <em>International Conference on Computer Vision.</em> <nobr class="links" style="font-weight: 600;"> [<a href="/assets/pdf/hsdt_iccv_2023_poster.pdf" target="_blank">Poster</a>] [<a href="https://github.com/Zeqiang-Lai/HSDT" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai</em>, Chenggang Yan, and <a href="https://ying-fu.github.io/" rel="external nofollow noopener" target="_blank">Ying Fu</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/man.png"></div> <div id="lai2022man" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2301.11525" rel="external nofollow noopener" target="_blank">Mixed Attention Network for Hyperspectral Image Denoising</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Preprint, </nobr> <em>arXiv preprint arXiv:2301.11525.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/Zeqiang-Lai/MAN" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai</em>, and <a href="https://ying-fu.github.io/" rel="external nofollow noopener" target="_blank">Ying Fu</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hsi_refsr.png"></div> <div id="lai2022refhsisr" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2302.06298" rel="external nofollow noopener" target="_blank">Hyperspectral Image Super Resolution with Real Unaligned RGB Guidance</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> TNNLS, </nobr> <em>IEEE Transactions on Neural Networks and Learning Systems.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://zeqiang-lai.github.io/HSI-RefSR/" target="_blank">Website</a>] [<a href="https://github.com/Zeqiang-Lai/HSI-RefSR" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai</em>, <a href="https://ying-fu.github.io/" rel="external nofollow noopener" target="_blank">Ying Fu</a>, and <a href="https://ieeexplore.ieee.org/author/37293680000" rel="external nofollow noopener" target="_blank">Jun Zhang</a> </div> </div> </div> </li> </ol> <h3 class="year">2021</h3> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/dphsir.png"></div> <div id="lai2022dphsir" class="col-sm-9"> <span class="title" style="font-size: 15.5px;"> <a href="https://arxiv.org/abs/2209.08240" rel="external nofollow noopener" target="_blank">Deep plug-and-play prior for hyperspectral image restoration</a></span> <br> <span class="periodical"> <nobr style="color:darkcyan; font-weight: 600;"> Neurocomputing, </nobr> <em>Elsevier Neurocomputing.</em> <nobr class="links" style="font-weight: 600;"> [<a href="https://github.com/Zeqiang-Lai/DPHSIR" target="_blank" rel="external nofollow noopener">Code</a>] </nobr> </span> <br> <div class="author"> <em>Zeqiang Lai</em>, <a href="https://kxwei.net/" rel="external nofollow noopener" target="_blank">Kaixuan Wei</a>, and <a href="https://ying-fu.github.io/" rel="external nofollow noopener" target="_blank">Ying Fu</a> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Zeqiang Lai. Based on the <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. template by <a href="https://tsong.me/" rel="external nofollow noopener" target="_blank">Jiaming Song</a>.  Last updated: September 29, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0FN7JHVVEP"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0FN7JHVVEP");</script> </body> </html>